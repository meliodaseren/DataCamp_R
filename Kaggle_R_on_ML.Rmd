---
title: "Kaggle R Tutorial on Machine Learning - R Notebook"
output: html_notebook
---

> This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

> Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

> Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

> When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

***

#### Titanic: Machine Learning from Disaster
https://www.kaggle.com/c/titanic/data

#### Install packages
```{r}
install.packages(rpart)
install.packages(rattle)
install.packages(rpart.plot)
install.packages(RColorBrewer)
install.packages(randomForest)
```

## Raising anchor

### Set Sail
```{r}
# Import the training set: train
train_url <- "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv"
train <- read.csv(train_url)

# Import the testing set: test
test_url <- "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv"
test <- read.csv(test_url)

# Print train and test to the console
train
test
```

### Understanding your data
#### Rose vs Jack, or Female vs Male
```{r}
# Your train and test set are still loaded
str(train)
str(test)

# Survival rates in absolute numbers
table(train$Survived)

# Survival rates in proportions
prop.table(table(train$Survived))
  
# Two-way comparison: Sex and Survived
table(train$Sex, train$Survived)

# Two-way comparison: row-wise proportions
prop.table(table(train$Sex, train$Survived), 1)
# prop.table(table(train$Sex, train$Survived), 2)
```

#### Does age play a role?
```{r}
# Create the column child, and indicate whether child or no child
train$Child <- NA
train$Child[train$Age < 18] <- 1
train$Child[train$Age >= 18] <- 0

# Two-way comparison
table(train$Child)
prop.table(table(train$Child))
prop.table(table(train$Child, train$Survived), 1)
```

### Making your first predictions
```{r}
# Your train and test set are still loaded in
str(train)
str(test)

# Copy of test
test_one <- test

# Initialize a Survived column to 0
test_one$Survived = 0

# Set Survived to 1 if Sex equals "female"
test_one$Survived[test$Sex == "female"] <- 1

str(test_one)
```

## From icebergs to trees
### Intro to decision trees
Conceptually, the decision tree algorithm starts with all the data at the root node and scans all the variables for the best one to split on. Once a variable is chosen, you do the split and go down one level (or one node) and repeat. The final nodes at the bottom of the decision tree are known as terminal nodes, and the majority vote of the observations in that node determine how to predict for new observations that end up in that terminal node.
### Creating first decision tree
Inside [rpart](https://www.rdocumentation.org/packages/rpart/versions/4.1-11), there is the ```rpart()``` function to build your first decision tree. The function takes multiple arguments:
* ```formula```: specifying variable of interest, and the variables used for prediction (e.g. ```formula = Survived ~ Sex + Age```).
* ```data```: The data set to build the decision tree (here ```train```).
* ```method```: Type of prediction you want. We want to predict a categorical variable, so classification: ```method = "class"```.
```{r}
# Load in the R package
library(rpart)

# Build the decision tree
my_tree_two <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
                     data = train,
                     method = "class")

# Visualize the decision tree using plot() and text()
plot(my_tree_two)
text(my_tree_two)

# Load in the packages to build a fancy plot
library(rattle)
library(rpart.plot)
library(RColorBrewer)

# Time to plot your fancy tree
fancyRpartPlot(my_tree_two)

```

### Interpreting your decision tree
Based on your decision tree, variables **"Sex"**, **"Age"**, **"Pclass"**, **"SibSp"**, **"Fare"** play the most important role to determine whether or not a passenger will survive.

### Predict and submit to Kaggle
```{r}
# my_tree_two and test are available in the workspace
my_tree_two
test

# Make predictions on the test set
  # my_tree_two is the tree model you've just built
  # test is the data set to build the preditions for
  # type = "class" specifies that you want to classify observations
my_prediction <- predict(my_tree_two, newdata = test, type = "class")


# Convert predictions to a CSV file with exactly 418 entries and 2 columns PassengerId and Survived

# Finish the data.frame() call
my_solution <- data.frame(PassengerId = test$PassengerId, Survived = my_prediction)

# Use nrow() on my_solution
nrow(my_solution)

# Finish the write.csv() call
write.csv(my_solution, file = "my_solution1.csv", row.names = FALSE)
```

### Overfitting, the iceberg of decision trees
Maybe we can improve even more by making a more complex model? In rpart, the amount of detail is defined by two parameters:
* ```cp``` determines when the splitting up of the decision tree stops.
* ```minsplit``` determines the minimum amount of observations in a leaf of the tree.

In the ```super_model``` on the right, ```cp = 0``` (no stopping of splits) and ```minsplit = 2``` (smallest leaf possible). This will create the best model! Or not? Check out the resulting plot with:

```fancyRpartPlot(super_model)```

Looking complex, but using this model to make predictions won't give you a good score on Kaggle. Why? Because you created very specific rules based on the data in the training set. These very detailed rules are only relevant for the training set but cannot be generalized to unknown sets. You overfitted your tree. Always be aware of this danger!

```{r}
# Your train and test set are still loaded in

# Change this command
my_tree_three <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
                       data = train, method = "class",
                       control = rpart.control(minsplit = 50, cp = 0))

# Visualize my_tree_three
fancyRpartPlot(my_tree_three)
```

### Re-engineering our Titanic data set
While feature engineering is a discipline in itself, too broad to be covered here in detail, let's have have a look at a simple example and create a new predictive attribute: ```family_size```.

A valid assumption is that larger families need more time to get together on a sinking ship, and hence have less chance of surviving. Family size is determined by the variables ```SibSp``` and ```Parch```, which indicate the number of family members a certain passenger is traveling with. So when doing feature engineering, you add a new variable ```family_size```, which is the sum of ```SibSp``` and ```Parch``` plus one (the observation itself), to the test and train set.

```{r}
# train and test are available

# Create train_two
train_two <- train
train_two$family_size <- train_two$SibSp + train_two$Parch + 1

# Finish the command
my_tree_four <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked +family_size, data = train_two, method = "class")

# Visualize your new decision tree
fancyRpartPlot(my_tree_four)
```

### Passenger Title and survival rate
**This part only work on [DataCamp](https://campus.datacamp.com/courses/kaggle-r-tutorial-on-machine-learning/chapter-2-from-icebergs-to-trees?ex=7)**

```{r}
# train_new and test_new are available in the workspace

# Finish the command
my_tree_five <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title, data = train_new, method = "class")

# Visualize my_tree_five
fancyRpartPlot(my_tree_five)

# Make prediction
my_prediction <- predict(my_tree_five, test_new, type = "class")

# Make results ready for submission
my_solution <- data.frame(PassengerId = test_new$PassengerId, Survived = my_prediction)
write.csv(my_solution, file = "my_solution2.csv", row.names = FALSE)
```

## Improving Your Predictions Through Random Forests
### What is a Random Forest
http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/all_data.RData

```{r}
# All data, both training and test set
all_data

# Passenger on row 62 and 830 do not have a value for embarkment.
# Since many passengers embarked at Southampton, we give them the value S.
all_data$Embarked[c(62, 830)] <- "S"

# Factorize embarkment codes.
all_data$Embarked <- factor(all_data$Embarked)

# Passenger on row 1044 has an NA Fare value. Let's replace it with the median fare value.
all_data$Fare[1044] <- median(all_data$Fare, na.rm = TRUE)

# How to fill in missing Age values?
# We make a prediction of a passengers Age using the other variables and a decision tree model.
# This time you give method = "anova" since you are predicting a continuous variable.
library(rpart)
predicted_age <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + family_size,
                       data = all_data[!is.na(all_data$Age),], method = "anova")
all_data$Age[is.na(all_data$Age)] <- predict(predicted_age, all_data[is.na(all_data$Age),])

# Split the data back into a train set and a test set
train <- all_data[1:891,]
test <- all_data[892:1309,]
```

### A Random Forest analysis in R
https://www.rdocumentation.org/packages/randomForest/versions/4.6-12

```{r}
# train and test are available in the workspace
str(train)
str(test)

# Load in the package
library(randomForest)

# Set seed for reproducibility
set.seed(111)

# Apply the Random Forest Algorithm
my_forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title,
                          data = train, importance = TRUE, ntree = 1000)

# Make your prediction using the test set
my_prediction <- predict(my_forest, test)

# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions
my_solution <- data.frame(PassengerId = test$PassengerId, Survived = my_prediction)

# Write your solution away to a csv file with the name my_solution.csv
write.csv(my_solution, file = "my_solution3.csv", row.names = FALSE)
```

### Important variables
Your Random Forest object ```my_forest``` is still loaded in. Remember you set ```importance = TRUE```? Now you can see what variables are important using
```{r}
varImpPlot(my_forest)
```

Based on the two plots, variable "Title" has the highest impact on the model.
